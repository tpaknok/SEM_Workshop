---
output:
  html_document:
    code_folding: show
---
# Quick piecewiseSEM workshop

Toby Tsang 24-01-2024 

## Objectives
After this workshop, hopefully you will be able to \
1) Understand the differences between structural equation models and multiple regressions \
2) Interpret results from piecewiseSEM \
3) Build simple SEMs 

## Simulated example
We will use a simulated datset to illustrate the differences between SEMs and multiple regressions. \
First, generate some data. The details are not important. You only need to know \
**1) Z1 increases Y and 2) X increases Z1 and Z2**

```{r}
library(MASS)
V <- matrix(0.5,2,2)
diag(V) <- 1
set.seed(1218)
X <- rnorm(100) #draw 100 numbers from a normal distribution
correlated_noise <- mvrnorm(100,c(0,0),V) #correlated noise between Z1 and Z2
Z1 <- X*0.5+correlated_noise[,1] #Z1 is driven by X, plus some noise
Z2 <- X*0.2+correlated_noise[,2] #Z2 too. But the slope is 0.2 
Y <- Z1+rnorm(100) #Y is only determined by Z1
df <- data.frame(X=X,Y=Y,Z1=Z1,Z2=Z2)
cor(df) #check pariwise correlations
head(df) #look at the data
```

## Some simple regressions

Assume that you don't know how the data were generated. Let's say you are interested in the predictors of Y, Let's try to do some bivariate regression first.

```{r}
m1 <- lm(Y~X,data=df)
summary(m1)

m2 <- lm(Y~Z1,data=df)
summary(m2)

m3 <- lm(Y~Z2,data=df)
summary(m3)
```

## Multiple regressions

You might be interested in the effect of all variables, so you just throw all of them into a multiple regression. Also, a multiple regression can control the effect of different variables and better identify the independent effect of the variable of interest, given they are all highly correlated. For examples, if you put X and Z1 in, then you are looking at effects of X after controlling Z1 (and Z1 after controlling X). The statistical meaning between a multiple regression and bivariate regression, therefore, is very different. 

If you look at the results below, you might conclude that Z1 is the only important variable, but not X. However, we know that X and drive Z1, because we simulated the data!

```{r}
m4 <- lm(Y~X+Z1+Z2,data=df)
summary(m4)
```

This model is examining the direct effect of each variable. It doesn't really care about the indirect effects between variables. The number here is standardized effect size (i.e. in the unit of 1 SD), thus they don't match the regression table output, which present unstandarized slope.

```{r, echo=FALSE,message=FALSE,warning=FALSE}
require(piecewiseSEM)
SEM2 <- psem(m4)
plot(SEM2)
```

## So why do we need SEM?
The problem of multiple regression is that they can't tell the indirect effect of the predictors, such as how X affects Z1 and ultimately affects Y. 

Let's use piecewiseSEM and build the SEM for the simulated data. In piecewiseSEM, we build a SEM by including all individual models (also called component models) in the function **psem**.

Thus, in the following SEMs, we have three component models (m4,m5,m6)
```{r,message=FALSE,warning=FALSE}
require(piecewiseSEM)
m4 <- lm(Y~X+Z1+Z2,data=df)
m5 <- lm(Z1~X,data=df)
m6 <- lm(Z2~X,data=df)
SEM1 <- psem(m5,
             m6,
             m4)
summary(SEM1,.progressBar = F,conserve=T)
plot(SEM1)
```
## Challenge
Try comparing the multiple regression and SEM results! What are the similarities and differences between the two approaches?

## Missing link and model performance
Pay attention to thedirected separation test and the global goodness-of-fit. If the former is significant, it is telling you that the two variables are correlated. This is POTENTIALLY a missing link and you should consider it. For both goodness-of-fit, if p < 0.05, it indicates our model is a poor fit of the data.
I understand a lot of reviewers will not trust your model if any goodness-of-fit test shows p < 0.05. I never think this is a problem if the goal of your study is inference. It only becomes a problem if your goal is prediction. However, I am not asking you to fight about statistics in your ecological papers. If you want, you can always add missing links until p > 0.05 for both goodness-of-fit test.

To add missing link, first consider whether there are causality between variables. If I am not sure, I will merely add a correlated error between them (%~~%), indicating they are correlated only.
If we want to add a correlated error between Z2 and Z1

```{r}
SEM2 <-  psem(m5,
             m6,
             m4,
             Z2 %~~% Z1)
summary(SEM2,conserve=T,.progressBar = F)
plot(SEM2)
```

Also, I will try to be clear about adding links that are not originally hypothesized. (You really shouldn't pretend that you had the link hypothesized after psem told you it was missing!) For examples, I wrote something like this in my paper....

**If the directed separation test indicated a missing relationship between community synchrony and population variability, we added a correlated error among them, as the causality of this relationship was unexpected from our model.**

## Challenge
Now try to build another model, but this time we assume no link between Z2 and X. How will you build it?

```{r,class.source = 'fold-hide'}
m7 <- lm(Z2~1,data=df)
SEM3 <- psem(m5,
             m7,
             m4,
             Z2 %~~% Z1)

#This is different!!! see model selection below
SEM4 <- psem(m5,
             m4,
             Z2 %~~% Z1) 
```

## Model selection
Actually, if you add some links recommended by psem, you are already doing model selection. Model selection is a very broad topic and doesn't really have a standardized strategy - even though some strategies such as AIC are commonly used. In piecewiseSEM, you can also use AIC to evaluate different models.

```{r}
AIC(SEM2,SEM3,SEM4)
```
SEM4 (the model without m7) has a lower AIC than SEM2 (Lower AIC = better). But we know that the link between Z1 and X is correct. What's happening???? \

```{r}
AIC(m4)+AIC(m5)
AIC(SEM4)
AIC(m5)+AIC(m6)+AIC(m4)
AIC(SEM2)
```
Turns out that the AIC of the SEM function is merely summing all AICs of the component models. For example, SEM4 has m4 and m5...so this is just the sum of AIC(m4) and AIC(m6).

**Note that given how the AIC is calculated, it might make more sense to compare AIC of SEMs with the same number of component models (and of course they should have the same responses). If SEMs have different number of component models, this won't be a fair comparison.**

## Case study 

The figure below is extracted from Lee et al. 2023 (https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2745.14109). They are interested in how vegetation structure, fire history, and elevation interacts to determine ant species richness. This is their conceptual model (Ignore MNND and MPD). 

The data can be downloaded [here](https://github.com/tpaknok/SEM_Workshop/blob/main/SEM_Lee_et_al_2023.csv), or just use this code

```{r}
ant_url <- "https://github.com/tpaknok/SEM_Workshop/raw/main/SEM_Lee_et_al_2023.csv"
ant <- read.csv(ant_url)
head(ant)
```

```{r,echo=F,warning=F,message=F}
library(knitr)
library(kableExtra)
library(tidyverse)
var_table <- data.frame(Name=c("Ele","TWI","Insol","Fire","Spp.richness","veg_pca1"),
           Description=c("Elevation (m)","Topographic wetness index","Incoming solar radiation","The year of last fire","Number of ant species","Vegetation PCA1 score"))
kable(var_table,caption="Variable descriptions") %>%   
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

Conceptual figure
```{r out.width="100%",echo=FALSE}
url <- "https://github.com/tpaknok/SEM_Workshop/raw/main/Lee_et_al_2023_Fig.jpg"
knitr::include_graphics(url)

```

Can you help Roger build the SEM? Let's keep things simple and assume normal distribution for everything. Note that if we need to do this seriously there are other distributions to use. The datsaet has other statistical issues such as pseudoreplications too... (read the actual paper if you are interested)

**Before constructing the SEM, you should think about how vegetation, fire and topography variables interact? What's the direct and indirect effect to each other?**

Remember that there are few things to check after you build the model: 1) are all the hypothesized links included? 2) are the models consistent with the observed data, and 3) are there any missing links that we didn't consider in the coneptual model?

```{r, echo=FALSE, results = "hide"}
ant_m1 <- lm(veg_pca1~Ele+TWI+Insol+Fire,data=ant)
ant_m2 <- lm(Spp.richness~Ele+TWI+Insol+Fire+veg_pca1,data=ant)

SEM_ant <- psem(ant_m1,ant_m2)
summary(SEM_ant,conserve = T)
```
